
**Notes**

Summary
1. based on previous seq2seq model
2. consider speaker's style in dialogs
3. user embedding to model speaker's style
4. train speaker's embeddings with word embeddings
5. use different style for one person in case of multiple dialogs

Thoughts
1. persona model may be taken as a special context
2. solved inconsistence issues
3. "unstanding" is still left to solve, is it possile to work with knowledge graph?
4. how about if we model special domain knowledges with embeddings?

**Reference**

http://chuansong.me/n/478035652741
